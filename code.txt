# Analyse des donn√©es Netflix

Ce notebook pr√©sente une analyse du catalogue Netflix bas√©e sur les donn√©es du fichier `netflix_titles.csv`.  
Nous allons explorer l'√©volution des contenus ajout√©s au fil du temps, les types de contenus, les genres, et plus encore.

---

## 1. Importation des biblioth√®ques et chargement des donn√©es


import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Charger les donn√©es
df = pd.read_csv(r"C:\Users\demba\Desktop\netflix_titles.csv.zip")

# Nettoyer la colonne date_added
df['date_added'] = df['date_added'].astype(str).str.strip()
df['date_added'] = pd.to_datetime(df['date_added'], errors='coerce')

# Cr√©er des colonnes ann√©e et mois pour les analyses temporelles
df['year_added'] = df['date_added'].dt.year
df['month_added'] = df['date_added'].dt.month
df['year_month'] = df['date_added'].dt.to_period('M')

# Aper√ßu des donn√©es
print("Dimensions :", df.shape)
df.head()




# Supprimer les espaces autour des dates
df['date_added'] = df['date_added'].astype(str).str.strip()

# Convertir en datetime (format libre, Pandas s'adapte)
df['date_added'] = pd.to_datetime(df['date_added'], errors='coerce')  # 'coerce' remplace les dates invalides par NaT



df['year_added'] = df['date_added'].dt.year
df['month_added'] = df['date_added'].dt.month
import os



## 2. Analyse temporelle des ajouts

Nous allons analyser comment le catalogue Netflix a √©volu√© au fil des ann√©es.
# Cr√©e un dossier 'images' dans ton projet si pas d√©j√† fait
os.makedirs('images', exist_ok=True)

# Graphique avec taille r√©duite
df_year.plot(kind='bar', stacked=True, colormap='Set2', figsize=(8,4))

plt.title("Contenus ajout√©s sur Netflix par an")  # Emoji retir√© pour √©viter warning
plt.xlabel("Ann√©e")
plt.ylabel("Nombre de titres")
plt.xticks(rotation=45)
plt.tight_layout()

# Sauvegarde dans le dossier 'images'
plt.savefig("images/netflix_ajouts_par_an.png", dpi=150, bbox_inches='tight')

plt.show()



## 3. Analyse sp√©cifique aux films

Focus sur l‚Äô√©volution des films ajout√©s.
films = df[df['type'] == 'Movie']
films_per_year = films.groupby('year_added').size()

films_per_year.plot(kind='line', marker='o', color='red', figsize=(10,5))
plt.title("Films ajout√©s chaque ann√©e")
plt.xlabel("Ann√©e")
plt.ylabel("Nombre de films")
plt.grid(True)
plt.show()



## 4. Analyse sp√©cifique aux s√©ries

Focus sur l‚Äô√©volution des s√©ries ajout√©es.
series = df[df['type'] == 'TV Show']
series_per_year = series.groupby('year_added').size()

series_per_year.plot(kind='line', marker='o', color='blue', figsize=(10,5))
plt.title("S√©ries ajout√©es chaque ann√©e")
plt.xlabel("Ann√©e")
plt.ylabel("Nombre de s√©ries")
plt.grid(True)
plt.show()




## 5. Analyse mensuelle des ajouts

Observation des ajouts mensuels pour d√©tecter des tendances saisonni√®res.
monthly = df.groupby('year_month').size()

monthly.plot(kind='line', linewidth=2, color='purple', figsize=(12,5))
plt.title("Nombre total de titres ajout√©s par mois")
plt.xlabel("Date")
plt.ylabel("Nombre de titres")
plt.grid(True)
plt.tight_layout()
plt.show()



## Conclusion

- Le catalogue Netflix a connu une croissance rapide entre 2015 et 2019.  
- Les ajouts semblent ralentir depuis 2020, probablement √† cause de facteurs externes (pand√©mie, strat√©gies de contenu).  
- Les films et s√©ries ont des tendances d‚Äôajout distinctes √† observer plus en d√©tail.

---

Tu peux poursuivre cette analyse en √©tudiant les genres, pays d‚Äôorigine, r√©alisateurs, etc.


üìÜ Analyse mensuelle des ajouts sur Netflix
Cette section observe l'√©volution du nombre de titres ajout√©s chaque mois, permettant de d√©tecter des tendances ou des pics saisonniers dans la strat√©gie de publication de Netflix.

‚úÖ √âtapes :
Cr√©er la colonne year_month (ann√©e + mois)

Grouper les donn√©es par mois

G√©n√©rer le graphique

Sauvegarder l‚Äôimage pour l‚Äôint√©grer dans le README.md

import os
import matplotlib.pyplot as plt

# 1. Cr√©er la colonne 'year_month' si elle n'existe pas d√©j√†
df['year_month'] = df['date_added'].dt.to_period('M')

# 2. Grouper par mois
monthly = df.groupby('year_month').size()

# 3. Cr√©er un dossier 'images' s'il n'existe pas (pour sauvegarder le graphique)
os.makedirs('images', exist_ok=True)

# 4. Tracer le graphique
plt.figure(figsize=(12, 5))
monthly.plot(kind='line', linewidth=2, color='purple')
plt.title("üìÜ Nombre total de titres ajout√©s par mois")
plt.xlabel("Date")
plt.ylabel("Nombre de titres")
plt.grid(True)
plt.tight_layout()

# 5. Sauvegarder l‚Äôimage
plt.savefig("images/netflix_mensuel.png", dpi=150, bbox_inches='tight')
plt.show()






projet 2

le chargement, nettoyage, exploration et pr√©paration des donn√©es

import pandas as pd

# 1. Chargement des donn√©es depuis le fichier CSV
df = pd.read_csv(r"C:\Users\arbi\Desktop\PROJET2\covid_19_clean_complete.csv")

# 2. Affichage des premi√®res lignes pour v√©rifier le chargement
print(df.head(10))

# 3. V√©rification des types et infos g√©n√©rales
print(df.info())

# 4. Comptage des valeurs manquantes par colonne
print(df.isnull().sum())

# 5. Suppression des doublons √©ventuels
df = df.drop_duplicates()

# 6. Conversion de la colonne 'Date' en format datetime
df['Date'] = pd.to_datetime(df['Date'])

# 7. Analyse rapide des valeurs manquantes apr√®s nettoyage
print(df.isnull().sum())

# 8. Si tu veux, tu peux afficher des statistiques descriptives
print(df.describe())

# 9. Agr√©gation des donn√©es au niveau pays et date (somme des cas)
df_agg = df.groupby(['Country/Region', 'Date']).agg({
    'Confirmed': 'sum',
    'Deaths': 'sum',
    'Recovered': 'sum',
    'Active': 'sum'
}).reset_index()

# 10. V√©rification du r√©sultat de l'agr√©gation
print(df_agg.head(10))

# 11. Exemple : affichage des 10 pays les plus touch√©s au dernier jour disponible
last_date = df_agg['Date'].max()
df_last = df_agg[df_agg['Date'] == last_date]
top_countries = df_last.sort_values('Confirmed', ascending=False).head(10)
print(top_countries[['Country/Region', 'Confirmed', 'Deaths', 'Recovered']])





MODELISATION regression lineaire simple
import pandas as pd
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt

# 1. Chargement des donn√©es (ici on suppose que le fichier est propre et nettoy√©)
df = pd.read_csv(r"C:\Users\arbi\Desktop\PROJET2\covid_19_clean_complete.csv")

# 2. Nettoyage basique
df = df.drop_duplicates()
df['Date'] = pd.to_datetime(df['Date'])

# 3. Agr√©gation des donn√©es par pays et date
df_agg = df.groupby(['Country/Region', 'Date']).agg({
    'Confirmed': 'sum',
    'Deaths': 'sum',
    'Recovered': 'sum'
}).reset_index()

# 4. S√©lection du pays (exemple: France)
country = 'France'
df_country = df_agg[df_agg['Country/Region'] == country].copy()
df_country = df_country.sort_values('Date')

# 5. Cr√©ation d'une variable "Day" (nombre de jours depuis la premi√®re date)
df_country['Day'] = (df_country['Date'] - df_country['Date'].min()).dt.days

# 6. Pr√©paration des donn√©es pour la mod√©lisation
X = df_country[['Day']]    # Variable ind√©pendante
y = df_country['Confirmed'] # Variable cible

# 7. Division des donn√©es en train/test (80% train, 20% test)
split = int(0.8 * len(df_country))
X_train, X_test = X[:split], X[split:]
y_train, y_test = y[:split], y[split:]

# 8. Cr√©ation et entra√Ænement du mod√®le de r√©gression lin√©aire
model = LinearRegression()
model.fit(X_train, y_train)

# 9. Pr√©diction sur l'ensemble test
y_pred = model.predict(X_test)

# 10. √âvaluation du mod√®le
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print(f"Mean Squared Error (MSE): {mse:.2f}")
print(f"Coefficient de d√©termination (R^2): {r2:.2f}")

# 11. Visualisation des pr√©dictions vs donn√©es r√©elles
plt.figure(figsize=(10,6))
plt.scatter(X_test, y_test, color='blue', label='Donn√©es r√©elles')
plt.plot(X_test, y_pred, color='red', linewidth=2, label='Pr√©dictions')
plt.xlabel('Jour depuis d√©but')
plt.ylabel('Cas confirm√©s')
plt.title(f'Pr√©diction des cas confirm√©s COVID-19 en {country} (R√©gression Lin√©aire)')
plt.legend()
plt.show()

# 12. Pr√©diction pour les 7 prochains jours
future_days = 7
last_day = df_country['Day'].max()
future_X = np.array([last_day + i for i in range(1, future_days + 1)]).reshape(-1,1)
future_pred = model.predict(future_X)

print("\nPr√©dictions des cas confirm√©s pour les prochains jours :")
for i, pred in enumerate(future_pred, 1):
    print(f"Jour +{i}: {int(pred)} cas confirm√©s (pr√©diction)")

# 13. Visualisation des donn√©es r√©elles + pr√©dictions futures
plt.figure(figsize=(10,6))
plt.plot(df_country['Day'], df_country['Confirmed'], label='Donn√©es r√©elles')
plt.plot(future_X, future_pred, label='Pr√©dictions futures', linestyle='--', color='orange')
plt.xlabel('Jour depuis d√©but')
plt.ylabel('Cas confirm√©s')
plt.title(f'Pr√©dictions des cas confirm√©s COVID-19 en {country} (futurs {future_days} jours)')
plt.legend()
plt.show()


modelisation random forest


import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt

# 1. Charger les donn√©es
df = pd.read_csv(r"C:\Users\arbi\Desktop\PROJET2\covid_19_clean_complete.csv")

# 2. Nettoyage de base
df = df.drop_duplicates()
df['Date'] = pd.to_datetime(df['Date'])

# 3. Agr√©ger par pays et date
df_agg = df.groupby(['Country/Region', 'Date']).agg({
    'Confirmed': 'sum',
    'Deaths': 'sum',
    'Recovered': 'sum'
}).reset_index()

# 4. Filtrer le pays (ex: France)
country = 'France'
df_country = df_agg[df_agg['Country/Region'] == country].copy()
df_country = df_country.sort_values('Date')

# 5. Cr√©er une variable "Day" (jours depuis d√©but)
df_country['Day'] = (df_country['Date'] - df_country['Date'].min()).dt.days

# 6. Pr√©parer features et cibles multi-sortie
X = df_country[['Day']]
y = df_country[['Confirmed', 'Deaths', 'Recovered']]

# 7. Diviser en train/test (80/20)
split = int(0.8 * len(df_country))
X_train, X_test = X[:split], X[split:]
y_train, y_test = y[:split], y[split:]

# 8. Cr√©er et entra√Æner le mod√®le Random Forest multi-sortie
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# 9. Pr√©dire sur test
y_pred = model.predict(X_test)

# 10. √âvaluer la performance pour chaque cible
for i, target in enumerate(['Confirmed', 'Deaths', 'Recovered']):
    mse = mean_squared_error(y_test.iloc[:, i], y_pred[:, i])
    r2 = r2_score(y_test.iloc[:, i], y_pred[:, i])
    print(f"{target} - MSE: {mse:.2f}, R^2: {r2:.2f}")

# 11. Visualiser les pr√©dictions vs r√©els pour les cas confirm√©s
plt.figure(figsize=(12,8))
plt.subplot(3,1,1)
plt.plot(X_test, y_test['Confirmed'], label='R√©el Confirmed')
plt.plot(X_test, y_pred[:,0], label='Pr√©dit Confirmed', linestyle='--')
plt.legend()
plt.title('Cas confirm√©s')

plt.subplot(3,1,2)
plt.plot(X_test, y_test['Deaths'], label='R√©el Deaths')
plt.plot(X_test, y_pred[:,1], label='Pr√©dit Deaths', linestyle='--')
plt.legend()
plt.title('D√©c√®s')

plt.subplot(3,1,3)
plt.plot(X_test, y_test['Recovered'], label='R√©el Recovered')
plt.plot(X_test, y_pred[:,2], label='Pr√©dit Recovered', linestyle='--')
plt.legend()
plt.title('R√©cup√©r√©s')

plt.xlabel('Jour depuis d√©but')
plt.tight_layout()
plt.show()

# 12. Pr√©dictions pour les 7 prochains jours

import matplotlib.pyplot as plt
import numpy as np

# Donn√©es r√©elles (derniers jours) pour affichage
days_real = df_country['Day']
confirmed_real = df_country['Confirmed']
deaths_real = df_country['Deaths']
recovered_real = df_country['Recovered']

# Pr√©paration des jours futurs
future_days = 7
last_day = days_real.max()
future_X = np.array([last_day + i for i in range(1, future_days + 1)]).reshape(-1, 1)

# Pr√©dictions
future_pred = model.predict(future_X)

# Tracer les graphiques
plt.figure(figsize=(14, 8))

# Confirmed
plt.subplot(3,1,1)
plt.plot(days_real, confirmed_real, label='Confirm√©s r√©els')
plt.plot(future_X.flatten(), future_pred[:, 0], 'r--', label='Confirm√©s pr√©dits')
plt.title('Cas Confirm√©s')
plt.xlabel('Jour depuis d√©but')
plt.ylabel('Nombre de cas')
plt.legend()

# Deaths
plt.subplot(3,1,2)
plt.plot(days_real, deaths_real, label='D√©c√®s r√©els')
plt.plot(future_X.flatten(), future_pred[:, 1], 'r--', label='D√©c√®s pr√©dits')
plt.title('D√©c√®s')
plt.xlabel('Jour depuis d√©but')
plt.ylabel('Nombre de cas')
plt.legend()

# Recovered
plt.subplot(3,1,3)
plt.plot(days_real, recovered_real, label='R√©tablis r√©els')
plt.plot(future_X.flatten(), future_pred[:, 2], 'r--', label='R√©tablis pr√©dits')
plt.title('R√©tablis')
plt.xlabel('Jour depuis d√©but')
plt.ylabel('Nombre de cas')
plt.legend()

plt.tight_layout()
plt.show()
